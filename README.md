# 3D-endoscopy
monocular depth estimation of endoscopic polyps using zero shot learning by learning key frames.

Depth estimation in endoscopic video frames imparts clinical relevance to a physician. 3D reconstruction of the monocular images helps in diagnosis, and surgical planning. In this project, a Monocular Depth Estimation (MDE) technique in a deep learning-based framework is used for 3D reconstruction of the polyps. Since ground truth depth maps are unavailable, a transfer learning approach is adopted in our work. The deep network used in our model is trained on various 3D datasets to cater to zero-shot learning applications. After depth estimation, a keyframe selection strategy is adopted.   

The key-frames summarize the entire endoscopic video sequence. This method discards low quality and clinically irrelevant frames while the most informative frames are retained. A three-criteria selection approach has been used for the proposed work. It considers moment distance, edge magnitude as given by depth maps, and the number of key-points given by the ORB feature descriptor as the selection criteria. Adaptive thresholding is used to combine the above measures to select the best frames in a sequence. Finally, depth maps are used to reconstruct the 3D surface of the polyp region. A GUI is devised to show the reconstructed surface. It gives the surgeon a real-time 3D view of the polyp surface.  This helps in analysing the characteristics of polyp in a better way.  

 Through my masterâ€™s project, I developed a keen interest in research in the Computer vision domain. I learned to implement deep learning models for depth estimation using the transfer learning approach. The main challenges were extreme variability in video frames, thus complicating the process of video summarization. I learnt frameworks like Pytorch and Keras while working on my project. I am going to communicate my work to a peer-reviewed journal. Furthermore, I wish to extend my findings into building an AR model for viewing the reconstructed frames.
